nohup: ignoring input
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190128': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730113351_a604ba41-2cb3-4392-8dc9-167af73d499b): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730113351_a604ba41-2cb3-4392-8dc9-167af73d499b); Time taken: 0.389 seconds
INFO  : Executing command(queryId=hive_20200730113351_a604ba41-2cb3-4392-8dc9-167af73d499b): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730113351_a604ba41-2cb3-4392-8dc9-167af73d499b); Time taken: 0.012 seconds
INFO  : OK
No rows affected (0.469 seconds)
INFO  : Compiling command(queryId=hive_20200730113351_3b41df97-915a-4b03-8e32-9ec8f6f219a9): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190128"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730113351_3b41df97-915a-4b03-8e32-9ec8f6f219a9); Time taken: 0.222 seconds
INFO  : Executing command(queryId=hive_20200730113351_3b41df97-915a-4b03-8e32-9ec8f6f219a9): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190128"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730113351_3b41df97-915a-4b03-8e32-9ec8f6f219a9); Time taken: 1.743 seconds
INFO  : OK
No rows affected (2.39 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730113400_eaa3c756-7fc9-4a84-8fa9-b27142e6bebd): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730113400_eaa3c756-7fc9-4a84-8fa9-b27142e6bebd); Time taken: 0.429 seconds
INFO  : Executing command(queryId=hive_20200730113400_eaa3c756-7fc9-4a84-8fa9-b27142e6bebd): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730113400_eaa3c756-7fc9-4a84-8fa9-b27142e6bebd); Time taken: 0.003 seconds
INFO  : OK
No rows affected (0.506 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 11:34:04 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 11:34:04 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 11:34:04 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 11:34:04 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 11:34:04 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 11:34:04 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 11:34:04 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 11:34:06 INFO tool.CodeGenTool: Beginning code generation
20/07/30 11:34:06 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 11:34:08 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/e6f91bcdb809b07da4dda10e6cc4c2f3/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 11:34:08 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/e6f91bcdb809b07da4dda10e6cc4c2f3/QueryResult.jar
20/07/30 11:34:08 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-01-28' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-01-29' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 11:34:22 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 11:34:22 INFO tool.ImportTool: Upper bound value: '2019-01-28'
20/07/30 11:34:22 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 11:34:22 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 11:34:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 11:34:22 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 11:34:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 11:34:23 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596080063245
20/07/30 11:34:24 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 11:34:24 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 11:34:24 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 11:34:24 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 11:34:24 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 11:34:24 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 11:34:24 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596080064956
20/07/30 11:34:24 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 1s
20/07/30 11:34:25 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 11:34:25 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596080065569, maxDate=1596684865569, sequenceNumber=53733, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 11:34:25 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596080065569, maxDate=1596684865569, sequenceNumber=53733, masterKeyId=57)
20/07/30 11:34:25 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14787
20/07/30 11:34:29 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 11:34:30 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 11:34:30 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 11:34:30 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 11:34:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14787
20/07/30 11:34:30 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596080065569, maxDate=1596684865569, sequenceNumber=53733, masterKeyId=57)]
20/07/30 11:34:30 INFO conf.Configuration: resource-types.xml not found
20/07/30 11:34:30 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 11:34:31 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14787
20/07/30 11:34:31 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14787/
20/07/30 11:34:31 INFO mapreduce.Job: Running job: job_1594011529082_14787
20/07/30 11:34:40 INFO mapreduce.Job: Job job_1594011529082_14787 running in uber mode : false
20/07/30 11:34:40 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 12:04:50 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 12:04:50 INFO mapreduce.Job: Job job_1594011529082_14787 completed successfully
20/07/30 12:04:50 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=11309909343
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7233720
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=1808430
		Total vcore-milliseconds taken by all map tasks=1808430
		Total megabyte-milliseconds taken by all map tasks=7407329280
	Map-Reduce Framework
		Map input records=7277122
		Map output records=7277122
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10748
		CPU time spent (ms)=1294120
		Physical memory (bytes) snapshot=2447413248
		Virtual memory (bytes) snapshot=5433073664
		Total committed heap usage (bytes)=2392850432
		Peak Map Physical memory (bytes)=2459934720
		Peak Map Virtual memory (bytes)=5433073664
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 12:04:50 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596081890936
20/07/30 12:04:54 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596081890936
20/07/30 12:04:54 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 3s
20/07/30 12:04:54 INFO mapreduce.ImportJobBase: Transferred 10.5332 GB in 1,831.4784 seconds (5.8892 MB/sec)
20/07/30 12:04:54 INFO mapreduce.ImportJobBase: Retrieved 7277122 records.
20/07/30 12:04:54 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190128
20/07/30 12:04:54 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 12:04:54 INFO tool.ImportTool:  --incremental append
20/07/30 12:04:54 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 12:04:54 INFO tool.ImportTool:   --last-value 2019-01-28
20/07/30 12:04:54 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730120501_14fe4df2-e58f-4889-988a-64a2120faf34): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-28")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120501_14fe4df2-e58f-4889-988a-64a2120faf34); Time taken: 0.427 seconds
INFO  : Executing command(queryId=hive_20200730120501_14fe4df2-e58f-4889-988a-64a2120faf34): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-28")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730120501_14fe4df2-e58f-4889-988a-64a2120faf34); Time taken: 0.108 seconds
INFO  : OK
No rows affected (0.615 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730120508_ba3bc478-2161-475a-8280-bee15e7095b4): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-28") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128 WHERE to_date("2019-01-28") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-29")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120508_ba3bc478-2161-475a-8280-bee15e7095b4); Time taken: 0.679 seconds
INFO  : Executing command(queryId=hive_20200730120508_ba3bc478-2161-475a-8280-bee15e7095b4): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-28") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128 WHERE to_date("2019-01-28") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-29")
INFO  : Query ID = hive_20200730120508_ba3bc478-2161-475a-8280-bee15e7095b4
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14797
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14797
INFO  : Hive on Spark Session Web UI URL: http://cdh19.irc.com:39250
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 12:05:28,245	Stage-0_0: 0(+1)/43	
INFO  : 2020-07-30 12:05:31,256	Stage-0_0: 0(+1)/43	
INFO  : 2020-07-30 12:05:32,259	Stage-0_0: 0(+3)/43	
INFO  : 2020-07-30 12:05:35,268	Stage-0_0: 0(+7)/43	
INFO  : 2020-07-30 12:05:38,279	Stage-0_0: 0(+11)/43	
INFO  : 2020-07-30 12:05:41,287	Stage-0_0: 0(+11)/43	
INFO  : 2020-07-30 12:05:44,296	Stage-0_0: 0(+11)/43	
INFO  : 2020-07-30 12:05:45,299	Stage-0_0: 0(+43)/43	
INFO  : 2020-07-30 12:05:47,304	Stage-0_0: 1(+42)/43	
INFO  : 2020-07-30 12:05:50,318	Stage-0_0: 6(+37)/43	
INFO  : 2020-07-30 12:05:51,321	Stage-0_0: 7(+36)/43	
INFO  : 2020-07-30 12:05:54,330	Stage-0_0: 7(+36)/43	
INFO  : 2020-07-30 12:05:56,335	Stage-0_0: 8(+35)/43	
INFO  : 2020-07-30 12:05:57,339	Stage-0_0: 13(+30)/43	
INFO  : 2020-07-30 12:06:00,349	Stage-0_0: 19(+24)/43	
INFO  : 2020-07-30 12:06:01,351	Stage-0_0: 30(+13)/43	
INFO  : 2020-07-30 12:06:02,353	Stage-0_0: 40(+3)/43	
INFO  : 2020-07-30 12:06:03,355	Stage-0_0: 43/43 Finished	
INFO  : Spark job[0] finished successfully in 37.16 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-28/.hive-staging_hive_2020-07-30_12-05-08_346_5779748234205750267-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-28/.hive-staging_hive_2020-07-30_12-05-08_346_5779748234205750267-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-01-28) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-28/.hive-staging_hive_2020-07-30_12-05-08_346_5779748234205750267-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730120508_ba3bc478-2161-475a-8280-bee15e7095b4); Time taken: 55.318 seconds
INFO  : OK
7,277,122 rows affected (56.037 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730120610_bea425d3-4ca8-4d6f-9ba3-c1915abcb28c): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120610_bea425d3-4ca8-4d6f-9ba3-c1915abcb28c); Time taken: 0.423 seconds
INFO  : Executing command(queryId=hive_20200730120610_bea425d3-4ca8-4d6f-9ba3-c1915abcb28c): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190128
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730120610_bea425d3-4ca8-4d6f-9ba3-c1915abcb28c); Time taken: 1.533 seconds
INFO  : OK
No rows affected (2.033 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190129': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730120623_9310f1a8-a8a8-45a4-a678-6e9e39e43699): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120623_9310f1a8-a8a8-45a4-a678-6e9e39e43699); Time taken: 0.403 seconds
INFO  : Executing command(queryId=hive_20200730120623_9310f1a8-a8a8-45a4-a678-6e9e39e43699): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730120623_9310f1a8-a8a8-45a4-a678-6e9e39e43699); Time taken: 0.01 seconds
INFO  : OK
No rows affected (0.486 seconds)
INFO  : Compiling command(queryId=hive_20200730120624_5f8b10d9-d41b-499f-9460-789eeaff0d91): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190129"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120624_5f8b10d9-d41b-499f-9460-789eeaff0d91); Time taken: 0.23 seconds
INFO  : Executing command(queryId=hive_20200730120624_5f8b10d9-d41b-499f-9460-789eeaff0d91): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190129"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730120624_5f8b10d9-d41b-499f-9460-789eeaff0d91); Time taken: 1.606 seconds
INFO  : OK
No rows affected (1.856 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730120632_d333ca71-e360-47ef-b5a3-41aa62e7d724): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730120632_d333ca71-e360-47ef-b5a3-41aa62e7d724); Time taken: 0.422 seconds
INFO  : Executing command(queryId=hive_20200730120632_d333ca71-e360-47ef-b5a3-41aa62e7d724): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730120632_d333ca71-e360-47ef-b5a3-41aa62e7d724); Time taken: 0.003 seconds
INFO  : OK
No rows affected (0.498 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 12:06:36 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 12:06:36 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 12:06:36 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 12:06:36 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 12:06:36 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 12:06:36 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 12:06:36 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 12:06:39 INFO tool.CodeGenTool: Beginning code generation
20/07/30 12:06:40 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 12:06:42 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/aa18e4f37ea64fa3ee03a65cadcace28/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 12:06:42 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/aa18e4f37ea64fa3ee03a65cadcace28/QueryResult.jar
20/07/30 12:06:42 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-01-29' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-01-30' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 12:07:08 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 12:07:08 INFO tool.ImportTool: Upper bound value: '2019-01-29'
20/07/30 12:07:08 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 12:07:08 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 12:07:08 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 12:07:10 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 12:07:10 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 12:07:10 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596082030826
20/07/30 12:07:13 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 12:07:13 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 12:07:13 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 12:07:14 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 12:07:14 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 12:07:14 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 12:07:14 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596082034775
20/07/30 12:07:14 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 3s
20/07/30 12:07:16 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 12:07:16 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596082036738, maxDate=1596686836738, sequenceNumber=53761, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 12:07:16 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596082036738, maxDate=1596686836738, sequenceNumber=53761, masterKeyId=57)
20/07/30 12:07:16 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14798
20/07/30 12:07:23 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 12:07:25 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 12:07:25 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 12:07:25 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 12:07:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14798
20/07/30 12:07:25 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596082036738, maxDate=1596686836738, sequenceNumber=53761, masterKeyId=57)]
20/07/30 12:07:26 INFO conf.Configuration: resource-types.xml not found
20/07/30 12:07:26 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 12:07:26 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14798
20/07/30 12:07:26 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14798/
20/07/30 12:07:26 INFO mapreduce.Job: Running job: job_1594011529082_14798
20/07/30 12:07:35 INFO mapreduce.Job: Job job_1594011529082_14798 running in uber mode : false
20/07/30 12:07:35 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 12:36:43 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 12:36:43 INFO mapreduce.Job: Job job_1594011529082_14798 completed successfully
20/07/30 12:36:44 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=10860563275
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6985216
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=1746304
		Total vcore-milliseconds taken by all map tasks=1746304
		Total megabyte-milliseconds taken by all map tasks=7152861184
	Map-Reduce Framework
		Map input records=7014882
		Map output records=7014882
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=9879
		CPU time spent (ms)=1257200
		Physical memory (bytes) snapshot=2074533888
		Virtual memory (bytes) snapshot=5429321728
		Total committed heap usage (bytes)=1803550720
		Peak Map Physical memory (bytes)=2114187264
		Peak Map Virtual memory (bytes)=5429321728
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 12:36:44 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596083804097
20/07/30 12:36:45 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596083804097
20/07/30 12:36:45 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 1s
20/07/30 12:36:45 INFO mapreduce.ImportJobBase: Transferred 10.1147 GB in 1,774.3567 seconds (5.8373 MB/sec)
20/07/30 12:36:45 INFO mapreduce.ImportJobBase: Retrieved 7014882 records.
20/07/30 12:36:45 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190129
20/07/30 12:36:45 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 12:36:45 INFO tool.ImportTool:  --incremental append
20/07/30 12:36:45 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 12:36:45 INFO tool.ImportTool:   --last-value 2019-01-29
20/07/30 12:36:45 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730123651_eeaa14e4-6524-421f-b0e9-4a0cd7649b6f): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-29")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123651_eeaa14e4-6524-421f-b0e9-4a0cd7649b6f); Time taken: 0.496 seconds
INFO  : Executing command(queryId=hive_20200730123651_eeaa14e4-6524-421f-b0e9-4a0cd7649b6f): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-29")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730123651_eeaa14e4-6524-421f-b0e9-4a0cd7649b6f); Time taken: 0.104 seconds
INFO  : OK
No rows affected (0.678 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730123658_d5665a94-40b5-45aa-833e-eeb99233faf3): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-29") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129 WHERE to_date("2019-01-29") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-30")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123658_d5665a94-40b5-45aa-833e-eeb99233faf3); Time taken: 0.765 seconds
INFO  : Executing command(queryId=hive_20200730123658_d5665a94-40b5-45aa-833e-eeb99233faf3): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-29") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129 WHERE to_date("2019-01-29") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-30")
INFO  : Query ID = hive_20200730123658_d5665a94-40b5-45aa-833e-eeb99233faf3
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14807
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14807
INFO  : Hive on Spark Session Web UI URL: http://cdh12.irc.com:42256
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 12:37:15,466	Stage-0_0: 0(+1)/41	
INFO  : 2020-07-30 12:37:18,472	Stage-0_0: 0(+1)/41	
INFO  : 2020-07-30 12:37:19,483	Stage-0_0: 0(+3)/41	
INFO  : 2020-07-30 12:37:20,486	Stage-0_0: 0(+25)/41	
INFO  : 2020-07-30 12:37:21,489	Stage-0_0: 0(+31)/41	
INFO  : 2020-07-30 12:37:24,495	Stage-0_0: 0(+33)/41	
INFO  : 2020-07-30 12:37:27,503	Stage-0_0: 0(+33)/41	
INFO  : 2020-07-30 12:37:28,505	Stage-0_0: 0(+37)/41	
INFO  : 2020-07-30 12:37:31,512	Stage-0_0: 0(+37)/41	
INFO  : 2020-07-30 12:37:33,517	Stage-0_0: 0(+41)/41	
INFO  : 2020-07-30 12:37:35,522	Stage-0_0: 1(+40)/41	
INFO  : 2020-07-30 12:37:38,530	Stage-0_0: 7(+34)/41	
INFO  : 2020-07-30 12:37:41,536	Stage-0_0: 7(+34)/41	
INFO  : 2020-07-30 12:37:43,540	Stage-0_0: 15(+26)/41	
INFO  : 2020-07-30 12:37:44,542	Stage-0_0: 18(+23)/41	
INFO  : 2020-07-30 12:37:45,545	Stage-0_0: 26(+15)/41	
INFO  : 2020-07-30 12:37:46,548	Stage-0_0: 36(+5)/41	
INFO  : 2020-07-30 12:37:48,553	Stage-0_0: 40(+1)/41	
INFO  : 2020-07-30 12:37:49,555	Stage-0_0: 41/41 Finished	
INFO  : Spark job[0] finished successfully in 36.14 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-29/.hive-staging_hive_2020-07-30_12-36-58_742_6825350665354913261-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-29/.hive-staging_hive_2020-07-30_12-36-58_742_6825350665354913261-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-01-29) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-29/.hive-staging_hive_2020-07-30_12-36-58_742_6825350665354913261-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730123658_d5665a94-40b5-45aa-833e-eeb99233faf3); Time taken: 51.035 seconds
INFO  : OK
7,014,882 rows affected (51.843 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730123756_34621365-56cc-4edf-b28b-b879fc674653): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123756_34621365-56cc-4edf-b28b-b879fc674653); Time taken: 0.445 seconds
INFO  : Executing command(queryId=hive_20200730123756_34621365-56cc-4edf-b28b-b879fc674653): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190129
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730123756_34621365-56cc-4edf-b28b-b879fc674653); Time taken: 1.756 seconds
INFO  : OK
No rows affected (2.295 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190130': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730123810_ead29dd0-e97c-428b-9981-cf358c3547e9): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123810_ead29dd0-e97c-428b-9981-cf358c3547e9); Time taken: 0.372 seconds
INFO  : Executing command(queryId=hive_20200730123810_ead29dd0-e97c-428b-9981-cf358c3547e9): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730123810_ead29dd0-e97c-428b-9981-cf358c3547e9); Time taken: 0.009 seconds
INFO  : OK
No rows affected (0.441 seconds)
INFO  : Compiling command(queryId=hive_20200730123810_bb32a215-91e0-4a2e-97c9-44bbae082a2f): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190130"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123810_bb32a215-91e0-4a2e-97c9-44bbae082a2f); Time taken: 0.213 seconds
INFO  : Executing command(queryId=hive_20200730123810_bb32a215-91e0-4a2e-97c9-44bbae082a2f): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190130"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730123810_bb32a215-91e0-4a2e-97c9-44bbae082a2f); Time taken: 1.669 seconds
INFO  : OK
No rows affected (1.903 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730123818_46557716-7e1e-4083-a63e-e60c4fe42a0d): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730123818_46557716-7e1e-4083-a63e-e60c4fe42a0d); Time taken: 0.423 seconds
INFO  : Executing command(queryId=hive_20200730123818_46557716-7e1e-4083-a63e-e60c4fe42a0d): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730123818_46557716-7e1e-4083-a63e-e60c4fe42a0d); Time taken: 0.004 seconds
INFO  : OK
No rows affected (0.501 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 12:38:22 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 12:38:23 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 12:38:23 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 12:38:23 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 12:38:23 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 12:38:23 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 12:38:23 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 12:38:26 INFO tool.CodeGenTool: Beginning code generation
20/07/30 12:38:26 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 12:38:29 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/01edf1a002a7ec0a218dc9fe5c013a5c/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 12:38:29 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/01edf1a002a7ec0a218dc9fe5c013a5c/QueryResult.jar
20/07/30 12:38:29 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-01-30' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-01-31' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 12:38:56 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 12:38:56 INFO tool.ImportTool: Upper bound value: '2019-01-30'
20/07/30 12:38:56 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 12:38:56 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 12:38:56 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 12:38:58 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 12:38:58 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 12:38:58 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596083938757
20/07/30 12:39:00 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 12:39:00 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 12:39:00 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 12:39:00 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 12:39:00 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 12:39:04 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 12:39:04 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596083944107
20/07/30 12:39:04 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 5s
20/07/30 12:39:05 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 12:39:05 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596083945379, maxDate=1596688745379, sequenceNumber=53790, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 12:39:05 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596083945379, maxDate=1596688745379, sequenceNumber=53790, masterKeyId=57)
20/07/30 12:39:05 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14809
20/07/30 12:39:09 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 12:39:10 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 12:39:10 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 12:39:10 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 12:39:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14809
20/07/30 12:39:10 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596083945379, maxDate=1596688745379, sequenceNumber=53790, masterKeyId=57)]
20/07/30 12:39:10 INFO conf.Configuration: resource-types.xml not found
20/07/30 12:39:10 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 12:39:10 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14809
20/07/30 12:39:10 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14809/
20/07/30 12:39:10 INFO mapreduce.Job: Running job: job_1594011529082_14809
20/07/30 12:39:20 INFO mapreduce.Job: Job job_1594011529082_14809 running in uber mode : false
20/07/30 12:39:20 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 13:07:17 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 13:07:18 INFO mapreduce.Job: Job job_1594011529082_14809 completed successfully
20/07/30 13:07:18 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=10245200635
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6700384
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=1675096
		Total vcore-milliseconds taken by all map tasks=1675096
		Total megabyte-milliseconds taken by all map tasks=6861193216
	Map-Reduce Framework
		Map input records=6629664
		Map output records=6629664
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=9146
		CPU time spent (ms)=1171800
		Physical memory (bytes) snapshot=1691955200
		Virtual memory (bytes) snapshot=5429108736
		Total committed heap usage (bytes)=1704984576
		Peak Map Physical memory (bytes)=1698385920
		Peak Map Virtual memory (bytes)=5429108736
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 13:07:18 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596085638159
20/07/30 13:07:20 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596085638159
20/07/30 13:07:20 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 2s
20/07/30 13:07:20 INFO mapreduce.ImportJobBase: Transferred 9.5416 GB in 1,702.2129 seconds (5.7399 MB/sec)
20/07/30 13:07:20 INFO mapreduce.ImportJobBase: Retrieved 6629664 records.
20/07/30 13:07:21 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190130
20/07/30 13:07:21 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 13:07:21 INFO tool.ImportTool:  --incremental append
20/07/30 13:07:21 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 13:07:21 INFO tool.ImportTool:   --last-value 2019-01-30
20/07/30 13:07:21 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730130727_0175ebca-2db9-4061-b65c-50b93d760316): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-30")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130727_0175ebca-2db9-4061-b65c-50b93d760316); Time taken: 0.412 seconds
INFO  : Executing command(queryId=hive_20200730130727_0175ebca-2db9-4061-b65c-50b93d760316): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-30")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730130727_0175ebca-2db9-4061-b65c-50b93d760316); Time taken: 0.106 seconds
INFO  : OK
No rows affected (0.596 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730130734_7a8bf1a0-b13f-4a39-a17b-040d12e78b41): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-30") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130 WHERE to_date("2019-01-30") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-31")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130734_7a8bf1a0-b13f-4a39-a17b-040d12e78b41); Time taken: 0.794 seconds
INFO  : Executing command(queryId=hive_20200730130734_7a8bf1a0-b13f-4a39-a17b-040d12e78b41): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-30") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130 WHERE to_date("2019-01-30") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-01-31")
INFO  : Query ID = hive_20200730130734_7a8bf1a0-b13f-4a39-a17b-040d12e78b41
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14813
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14813
INFO  : Hive on Spark Session Web UI URL: http://cdh27.irc.com:33412
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 13:07:53,361	Stage-0_0: 0(+1)/39	
INFO  : 2020-07-30 13:07:56,370	Stage-0_0: 0(+1)/39	
INFO  : 2020-07-30 13:07:57,372	Stage-0_0: 0(+7)/39	
INFO  : 2020-07-30 13:07:58,375	Stage-0_0: 0(+9)/39	
INFO  : 2020-07-30 13:08:01,383	Stage-0_0: 0(+9)/39	
INFO  : 2020-07-30 13:08:02,386	Stage-0_0: 0(+11)/39	
INFO  : 2020-07-30 13:08:05,392	Stage-0_0: 0(+23)/39	
INFO  : 2020-07-30 13:08:06,395	Stage-0_0: 0(+24)/39	
INFO  : 2020-07-30 13:08:09,404	Stage-0_0: 0(+39)/39	
INFO  : 2020-07-30 13:08:10,407	Stage-0_0: 1(+38)/39	
INFO  : 2020-07-30 13:08:13,413	Stage-0_0: 1(+38)/39	
INFO  : 2020-07-30 13:08:15,416	Stage-0_0: 2(+37)/39	
INFO  : 2020-07-30 13:08:16,418	Stage-0_0: 7(+32)/39	
INFO  : 2020-07-30 13:08:19,426	Stage-0_0: 7(+32)/39	
INFO  : 2020-07-30 13:08:20,428	Stage-0_0: 15(+24)/39	
INFO  : 2020-07-30 13:08:21,429	Stage-0_0: 16(+23)/39	
INFO  : 2020-07-30 13:08:23,433	Stage-0_0: 18(+21)/39	
INFO  : 2020-07-30 13:08:24,435	Stage-0_0: 24(+15)/39	
INFO  : 2020-07-30 13:08:25,437	Stage-0_0: 39/39 Finished	
INFO  : Spark job[0] finished successfully in 34.13 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-30/.hive-staging_hive_2020-07-30_13-07-34_488_3470265720894725058-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-30/.hive-staging_hive_2020-07-30_13-07-34_488_3470265720894725058-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-01-30) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-30/.hive-staging_hive_2020-07-30_13-07-34_488_3470265720894725058-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730130734_7a8bf1a0-b13f-4a39-a17b-040d12e78b41); Time taken: 51.112 seconds
INFO  : OK
6,629,664 rows affected (51.951 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730130832_869a271e-6a63-4b50-bf7c-0e761b7cc7d3): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130832_869a271e-6a63-4b50-bf7c-0e761b7cc7d3); Time taken: 0.426 seconds
INFO  : Executing command(queryId=hive_20200730130832_869a271e-6a63-4b50-bf7c-0e761b7cc7d3): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190130
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730130832_869a271e-6a63-4b50-bf7c-0e761b7cc7d3); Time taken: 1.498 seconds
INFO  : OK
No rows affected (2.005 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190131': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730130845_956948cb-2356-4163-8173-6c6556cbe469): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130845_956948cb-2356-4163-8173-6c6556cbe469); Time taken: 0.405 seconds
INFO  : Executing command(queryId=hive_20200730130845_956948cb-2356-4163-8173-6c6556cbe469): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730130845_956948cb-2356-4163-8173-6c6556cbe469); Time taken: 0.009 seconds
INFO  : OK
No rows affected (0.483 seconds)
INFO  : Compiling command(queryId=hive_20200730130846_9ef13f0c-3b6e-46bf-b34e-c95f7ce4b0ff): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190131"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130846_9ef13f0c-3b6e-46bf-b34e-c95f7ce4b0ff); Time taken: 0.217 seconds
INFO  : Executing command(queryId=hive_20200730130846_9ef13f0c-3b6e-46bf-b34e-c95f7ce4b0ff): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190131"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730130846_9ef13f0c-3b6e-46bf-b34e-c95f7ce4b0ff); Time taken: 1.611 seconds
INFO  : OK
No rows affected (1.849 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730130854_512d4d6a-980a-4fd6-9179-907516057e0a): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730130854_512d4d6a-980a-4fd6-9179-907516057e0a); Time taken: 0.403 seconds
INFO  : Executing command(queryId=hive_20200730130854_512d4d6a-980a-4fd6-9179-907516057e0a): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730130854_512d4d6a-980a-4fd6-9179-907516057e0a); Time taken: 0.003 seconds
INFO  : OK
No rows affected (0.48 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 13:08:58 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 13:08:58 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 13:08:58 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 13:08:58 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 13:08:58 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 13:08:58 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 13:08:58 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 13:09:00 INFO tool.CodeGenTool: Beginning code generation
20/07/30 13:09:00 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 13:09:03 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/84396aec999b61d56524917ebb8db838/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 13:09:03 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/84396aec999b61d56524917ebb8db838/QueryResult.jar
20/07/30 13:09:03 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-01-31' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-02-01' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 13:09:25 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 13:09:25 INFO tool.ImportTool: Upper bound value: '2019-01-31'
20/07/30 13:09:25 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 13:09:25 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 13:09:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 13:09:26 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 13:09:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 13:09:26 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596085766823
20/07/30 13:09:28 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 13:09:28 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 13:09:28 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 13:09:28 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 13:09:28 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 13:09:29 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 13:09:29 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596085769187
20/07/30 13:09:29 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 2s
20/07/30 13:09:30 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 13:09:30 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596085770611, maxDate=1596690570611, sequenceNumber=53804, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 13:09:30 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596085770611, maxDate=1596690570611, sequenceNumber=53804, masterKeyId=57)
20/07/30 13:09:30 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14814
20/07/30 13:09:35 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 13:09:36 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 13:09:36 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 13:09:36 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 13:09:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14814
20/07/30 13:09:36 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596085770611, maxDate=1596690570611, sequenceNumber=53804, masterKeyId=57)]
20/07/30 13:09:36 INFO conf.Configuration: resource-types.xml not found
20/07/30 13:09:36 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 13:09:36 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14814
20/07/30 13:09:36 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14814/
20/07/30 13:09:36 INFO mapreduce.Job: Running job: job_1594011529082_14814
20/07/30 13:09:45 INFO mapreduce.Job: Job job_1594011529082_14814 running in uber mode : false
20/07/30 13:09:45 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 13:36:03 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 13:36:04 INFO mapreduce.Job: Job job_1594011529082_14814 completed successfully
20/07/30 13:36:04 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=9503590953
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Other local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6302296
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=1575574
		Total vcore-milliseconds taken by all map tasks=1575574
		Total megabyte-milliseconds taken by all map tasks=6453551104
	Map-Reduce Framework
		Map input records=6153968
		Map output records=6153968
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=8203
		CPU time spent (ms)=1087600
		Physical memory (bytes) snapshot=1540681728
		Virtual memory (bytes) snapshot=5426544640
		Total committed heap usage (bytes)=1685585920
		Peak Map Physical memory (bytes)=1605353472
		Peak Map Virtual memory (bytes)=5426544640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 13:36:04 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596087364154
20/07/30 13:36:04 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596087364154
20/07/30 13:36:04 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 0s
20/07/30 13:36:04 INFO mapreduce.ImportJobBase: Transferred 8.8509 GB in 1,597.9719 seconds (5.6718 MB/sec)
20/07/30 13:36:04 INFO mapreduce.ImportJobBase: Retrieved 6153968 records.
20/07/30 13:36:04 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190131
20/07/30 13:36:04 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 13:36:04 INFO tool.ImportTool:  --incremental append
20/07/30 13:36:04 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 13:36:04 INFO tool.ImportTool:   --last-value 2019-01-31
20/07/30 13:36:04 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730133611_ffe712ff-74fc-44bf-b140-be005da97b10): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-31")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133611_ffe712ff-74fc-44bf-b140-be005da97b10); Time taken: 0.41 seconds
INFO  : Executing command(queryId=hive_20200730133611_ffe712ff-74fc-44bf-b140-be005da97b10): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-01-31")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730133611_ffe712ff-74fc-44bf-b140-be005da97b10); Time taken: 0.102 seconds
INFO  : OK
No rows affected (0.595 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730133618_466f173a-ab68-46ad-8716-9e20c1c9650d): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-31") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131 WHERE to_date("2019-01-31") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-01")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133618_466f173a-ab68-46ad-8716-9e20c1c9650d); Time taken: 0.761 seconds
INFO  : Executing command(queryId=hive_20200730133618_466f173a-ab68-46ad-8716-9e20c1c9650d): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-01-31") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131 WHERE to_date("2019-01-31") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-01")
INFO  : Query ID = hive_20200730133618_466f173a-ab68-46ad-8716-9e20c1c9650d
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14818
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14818
INFO  : Hive on Spark Session Web UI URL: http://cdh20.irc.com:36769
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 13:36:38,792	Stage-0_0: 0(+1)/36	
INFO  : 2020-07-30 13:36:41,800	Stage-0_0: 0(+1)/36	
INFO  : 2020-07-30 13:36:42,803	Stage-0_0: 0(+4)/36	
INFO  : 2020-07-30 13:36:45,812	Stage-0_0: 0(+6)/36	
INFO  : 2020-07-30 13:36:48,818	Stage-0_0: 0(+6)/36	
INFO  : 2020-07-30 13:36:49,820	Stage-0_0: 0(+10)/36	
INFO  : 2020-07-30 13:36:50,824	Stage-0_0: 0(+36)/36	
INFO  : 2020-07-30 13:36:53,832	Stage-0_0: 0(+36)/36	
INFO  : 2020-07-30 13:36:56,840	Stage-0_0: 0(+36)/36	
INFO  : 2020-07-30 13:36:59,846	Stage-0_0: 3(+33)/36	
INFO  : 2020-07-30 13:37:02,853	Stage-0_0: 3(+33)/36	
INFO  : 2020-07-30 13:37:03,856	Stage-0_0: 8(+28)/36	
INFO  : 2020-07-30 13:37:04,858	Stage-0_0: 10(+26)/36	
INFO  : 2020-07-30 13:37:07,864	Stage-0_0: 10(+26)/36	
INFO  : 2020-07-30 13:37:09,868	Stage-0_0: 13(+23)/36	
INFO  : 2020-07-30 13:37:12,875	Stage-0_0: 13(+23)/36	
INFO  : 2020-07-30 13:37:13,877	Stage-0_0: 14(+22)/36	
INFO  : 2020-07-30 13:37:14,881	Stage-0_0: 30(+6)/36	
INFO  : 2020-07-30 13:37:15,884	Stage-0_0: 35(+1)/36	
INFO  : 2020-07-30 13:37:17,888	Stage-0_0: 36/36 Finished	
INFO  : Spark job[0] finished successfully in 41.14 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-31/.hive-staging_hive_2020-07-30_13-36-18_398_2363320046419341108-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-31/.hive-staging_hive_2020-07-30_13-36-18_398_2363320046419341108-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-01-31) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-01-31/.hive-staging_hive_2020-07-30_13-36-18_398_2363320046419341108-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730133618_466f173a-ab68-46ad-8716-9e20c1c9650d); Time taken: 59.63 seconds
INFO  : OK
6,153,968 rows affected (60.432 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730133725_6d8516c9-0676-42e7-b088-e5d7d8a8ddd5): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133725_6d8516c9-0676-42e7-b088-e5d7d8a8ddd5); Time taken: 0.431 seconds
INFO  : Executing command(queryId=hive_20200730133725_6d8516c9-0676-42e7-b088-e5d7d8a8ddd5): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190131
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730133725_6d8516c9-0676-42e7-b088-e5d7d8a8ddd5); Time taken: 1.618 seconds
INFO  : OK
No rows affected (2.12 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190201': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730133738_e9f2b081-0aab-4eac-8dd1-374d6ff31219): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133738_e9f2b081-0aab-4eac-8dd1-374d6ff31219); Time taken: 0.405 seconds
INFO  : Executing command(queryId=hive_20200730133738_e9f2b081-0aab-4eac-8dd1-374d6ff31219): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730133738_e9f2b081-0aab-4eac-8dd1-374d6ff31219); Time taken: 0.01 seconds
INFO  : OK
No rows affected (0.483 seconds)
INFO  : Compiling command(queryId=hive_20200730133738_2be251a4-f2b8-4c02-86a0-688727679fe1): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190201"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133738_2be251a4-f2b8-4c02-86a0-688727679fe1); Time taken: 0.223 seconds
INFO  : Executing command(queryId=hive_20200730133738_2be251a4-f2b8-4c02-86a0-688727679fe1): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190201"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730133738_2be251a4-f2b8-4c02-86a0-688727679fe1); Time taken: 1.549 seconds
INFO  : OK
No rows affected (1.795 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730133746_d80db366-f23f-4499-85e2-8df19328ff3f): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730133746_d80db366-f23f-4499-85e2-8df19328ff3f); Time taken: 0.408 seconds
INFO  : Executing command(queryId=hive_20200730133746_d80db366-f23f-4499-85e2-8df19328ff3f): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730133746_d80db366-f23f-4499-85e2-8df19328ff3f); Time taken: 0.003 seconds
INFO  : OK
No rows affected (0.482 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 13:37:50 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 13:37:51 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 13:37:51 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 13:37:51 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 13:37:51 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 13:37:51 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 13:37:51 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 13:37:52 INFO tool.CodeGenTool: Beginning code generation
20/07/30 13:37:54 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 13:37:56 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/1d4f0faad8736e0ac9eef7ef43d4808f/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 13:37:56 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/1d4f0faad8736e0ac9eef7ef43d4808f/QueryResult.jar
20/07/30 13:37:56 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-02-01' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-02-02' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 13:38:02 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 13:38:02 INFO tool.ImportTool: Upper bound value: '2019-02-01'
20/07/30 13:38:02 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 13:38:02 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 13:38:02 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 13:38:02 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 13:38:03 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 13:38:03 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596087483385
20/07/30 13:38:03 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 13:38:03 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 13:38:03 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 13:38:06 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 13:38:06 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 13:38:08 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 13:38:08 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596087488092
20/07/30 13:38:08 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 4s
20/07/30 13:38:08 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 13:38:08 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596087488783, maxDate=1596692288783, sequenceNumber=53821, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 13:38:08 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596087488783, maxDate=1596692288783, sequenceNumber=53821, masterKeyId=57)
20/07/30 13:38:08 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14820
20/07/30 13:38:11 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 13:38:12 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 13:38:12 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 13:38:12 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 13:38:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14820
20/07/30 13:38:12 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596087488783, maxDate=1596692288783, sequenceNumber=53821, masterKeyId=57)]
20/07/30 13:38:12 INFO conf.Configuration: resource-types.xml not found
20/07/30 13:38:12 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 13:38:12 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14820
20/07/30 13:38:12 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14820/
20/07/30 13:38:12 INFO mapreduce.Job: Running job: job_1594011529082_14820
20/07/30 13:38:22 INFO mapreduce.Job: Job job_1594011529082_14820 running in uber mode : false
20/07/30 13:38:22 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 14:00:44 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 14:00:44 INFO mapreduce.Job: Job job_1594011529082_14820 completed successfully
20/07/30 14:00:44 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=8250749382
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5358308
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=1339577
		Total vcore-milliseconds taken by all map tasks=1339577
		Total megabyte-milliseconds taken by all map tasks=5486907392
	Map-Reduce Framework
		Map input records=5371381
		Map output records=5371381
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=8765
		CPU time spent (ms)=974120
		Physical memory (bytes) snapshot=1610768384
		Virtual memory (bytes) snapshot=5418242048
		Total committed heap usage (bytes)=1633681408
		Peak Map Physical memory (bytes)=1626304512
		Peak Map Virtual memory (bytes)=5434138624
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 14:00:44 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596088844665
20/07/30 14:00:45 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596088844665
20/07/30 14:00:45 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 0s
20/07/30 14:00:45 INFO mapreduce.ImportJobBase: Transferred 7.6841 GB in 1,361.9426 seconds (5.7774 MB/sec)
20/07/30 14:00:45 INFO mapreduce.ImportJobBase: Retrieved 5371381 records.
20/07/30 14:00:45 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190201
20/07/30 14:00:45 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 14:00:45 INFO tool.ImportTool:  --incremental append
20/07/30 14:00:45 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 14:00:45 INFO tool.ImportTool:   --last-value 2019-02-01
20/07/30 14:00:45 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730140051_f9fce240-f2c2-4320-b835-5d73f4c2b3ab): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-02-01")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140051_f9fce240-f2c2-4320-b835-5d73f4c2b3ab); Time taken: 0.421 seconds
INFO  : Executing command(queryId=hive_20200730140051_f9fce240-f2c2-4320-b835-5d73f4c2b3ab): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-02-01")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730140051_f9fce240-f2c2-4320-b835-5d73f4c2b3ab); Time taken: 0.1 seconds
INFO  : OK
No rows affected (0.596 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730140058_c77193fa-1dee-43df-bf2d-27ed2dac2a4a): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-02-01") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201 WHERE to_date("2019-02-01") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-02")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140058_c77193fa-1dee-43df-bf2d-27ed2dac2a4a); Time taken: 0.645 seconds
INFO  : Executing command(queryId=hive_20200730140058_c77193fa-1dee-43df-bf2d-27ed2dac2a4a): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-02-01") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201 WHERE to_date("2019-02-01") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-02")
INFO  : Query ID = hive_20200730140058_c77193fa-1dee-43df-bf2d-27ed2dac2a4a
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14824
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14824
INFO  : Hive on Spark Session Web UI URL: http://cdh10.irc.com:34994
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 14:01:15,873	Stage-0_0: 0/31	
INFO  : 2020-07-30 14:01:18,881	Stage-0_0: 0/31	
INFO  : 2020-07-30 14:01:19,885	Stage-0_0: 0(+7)/31	
INFO  : 2020-07-30 14:01:21,890	Stage-0_0: 0(+19)/31	
INFO  : 2020-07-30 14:01:24,902	Stage-0_0: 0(+19)/31	
INFO  : 2020-07-30 14:01:27,908	Stage-0_0: 0(+19)/31	
INFO  : 2020-07-30 14:01:30,924	Stage-0_0: 0(+19)/31	
INFO  : 2020-07-30 14:01:31,928	Stage-0_0: 0(+31)/31	
INFO  : 2020-07-30 14:01:34,935	Stage-0_0: 1(+30)/31	
INFO  : 2020-07-30 14:01:37,943	Stage-0_0: 1(+30)/31	
INFO  : 2020-07-30 14:01:40,949	Stage-0_0: 6(+25)/31	
INFO  : 2020-07-30 14:01:41,951	Stage-0_0: 7(+24)/31	
INFO  : 2020-07-30 14:01:44,957	Stage-0_0: 7(+24)/31	
INFO  : 2020-07-30 14:01:46,963	Stage-0_0: 14(+17)/31	
INFO  : 2020-07-30 14:01:47,966	Stage-0_0: 27(+4)/31	
INFO  : 2020-07-30 14:01:48,968	Stage-0_0: 31/31 Finished	
INFO  : Spark job[0] finished successfully in 35.15 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-01/.hive-staging_hive_2020-07-30_14-00-58_880_6885737485046197231-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-01/.hive-staging_hive_2020-07-30_14-00-58_880_6885737485046197231-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-02-01) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-01/.hive-staging_hive_2020-07-30_14-00-58_880_6885737485046197231-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730140058_c77193fa-1dee-43df-bf2d-27ed2dac2a4a); Time taken: 50.352 seconds
INFO  : OK
5,371,381 rows affected (51.041 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730140156_1a44e524-b8ba-4d29-914c-fa7f1ec36868): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140156_1a44e524-b8ba-4d29-914c-fa7f1ec36868); Time taken: 0.394 seconds
INFO  : Executing command(queryId=hive_20200730140156_1a44e524-b8ba-4d29-914c-fa7f1ec36868): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190201
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730140156_1a44e524-b8ba-4d29-914c-fa7f1ec36868); Time taken: 1.521 seconds
INFO  : OK
No rows affected (1.994 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190202': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730140209_38ffffdf-bd2b-4f51-8437-618d697c2d46): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140209_38ffffdf-bd2b-4f51-8437-618d697c2d46); Time taken: 0.409 seconds
INFO  : Executing command(queryId=hive_20200730140209_38ffffdf-bd2b-4f51-8437-618d697c2d46): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730140209_38ffffdf-bd2b-4f51-8437-618d697c2d46); Time taken: 0.01 seconds
INFO  : OK
No rows affected (0.481 seconds)
INFO  : Compiling command(queryId=hive_20200730140209_4439324d-a230-4810-98f6-16dfa46e13df): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190202"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140209_4439324d-a230-4810-98f6-16dfa46e13df); Time taken: 0.207 seconds
INFO  : Executing command(queryId=hive_20200730140209_4439324d-a230-4810-98f6-16dfa46e13df): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190202"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730140209_4439324d-a230-4810-98f6-16dfa46e13df); Time taken: 1.672 seconds
INFO  : OK
No rows affected (1.901 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730140217_72a7d6ba-50e0-4526-a063-1337f52eea25): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730140217_72a7d6ba-50e0-4526-a063-1337f52eea25); Time taken: 0.425 seconds
INFO  : Executing command(queryId=hive_20200730140217_72a7d6ba-50e0-4526-a063-1337f52eea25): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730140217_72a7d6ba-50e0-4526-a063-1337f52eea25); Time taken: 0.004 seconds
INFO  : OK
No rows affected (0.5 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 14:02:21 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 14:02:22 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 14:02:22 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 14:02:22 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 14:02:22 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 14:02:22 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 14:02:22 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 14:02:24 INFO tool.CodeGenTool: Beginning code generation
20/07/30 14:02:24 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 14:02:27 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/eacf99b500b36171256572e5aa6c7b1f/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 14:02:27 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/eacf99b500b36171256572e5aa6c7b1f/QueryResult.jar
20/07/30 14:02:27 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-02-02' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-02-03' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 14:02:34 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 14:02:34 INFO tool.ImportTool: Upper bound value: '2019-02-02'
20/07/30 14:02:34 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 14:02:34 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 14:02:34 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 14:02:35 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 14:02:36 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 14:02:36 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596088956342
20/07/30 14:02:37 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 14:02:37 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 14:02:37 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 14:02:37 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 14:02:37 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 14:02:38 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 14:02:38 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596088958062
20/07/30 14:02:38 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 1s
20/07/30 14:02:39 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 14:02:39 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596088959580, maxDate=1596693759580, sequenceNumber=53831, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 14:02:39 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596088959580, maxDate=1596693759580, sequenceNumber=53831, masterKeyId=57)
20/07/30 14:02:39 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14825
20/07/30 14:02:44 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 14:02:45 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 14:02:45 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 14:02:45 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 14:02:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14825
20/07/30 14:02:45 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596088959580, maxDate=1596693759580, sequenceNumber=53831, masterKeyId=57)]
20/07/30 14:02:45 INFO conf.Configuration: resource-types.xml not found
20/07/30 14:02:45 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 14:02:45 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14825
20/07/30 14:02:45 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14825/
20/07/30 14:02:45 INFO mapreduce.Job: Running job: job_1594011529082_14825
20/07/30 14:02:54 INFO mapreduce.Job: Job job_1594011529082_14825 running in uber mode : false
20/07/30 14:02:54 INFO mapreduce.Job:  map 0% reduce 0%
20/07/30 14:19:17 INFO mapreduce.Job:  map 100% reduce 0%
20/07/30 14:19:17 INFO mapreduce.Job: Job job_1594011529082_14825 completed successfully
20/07/30 14:19:17 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=272822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=416
		HDFS: Number of bytes written=6039781663
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3920792
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=980198
		Total vcore-milliseconds taken by all map tasks=980198
		Total megabyte-milliseconds taken by all map tasks=4014891008
	Map-Reduce Framework
		Map input records=3950777
		Map output records=3950777
		Input split bytes=416
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=5207
		CPU time spent (ms)=675530
		Physical memory (bytes) snapshot=1259589632
		Virtual memory (bytes) snapshot=5418954752
		Total committed heap usage (bytes)=1617952768
		Peak Map Physical memory (bytes)=1383530496
		Peak Map Virtual memory (bytes)=5418954752
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
20/07/30 14:19:17 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596089957711
20/07/30 14:19:19 INFO processor.TeradataInputProcessor: input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596089957711
20/07/30 14:19:19 INFO processor.TeradataInputProcessor: the total elapsed time of input postprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 2s
20/07/30 14:19:19 INFO mapreduce.ImportJobBase: Transferred 5.625 GB in 1,003.3991 seconds (5.7405 MB/sec)
20/07/30 14:19:19 INFO mapreduce.ImportJobBase: Retrieved 3950777 records.
20/07/30 14:19:19 INFO util.AppendUtils: Appending to directory T80_PASSENGER_FLOW_MODIFY20190202
20/07/30 14:19:19 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
20/07/30 14:19:19 INFO tool.ImportTool:  --incremental append
20/07/30 14:19:19 INFO tool.ImportTool:   --check-column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 14:19:19 INFO tool.ImportTool:   --last-value 2019-02-02
20/07/30 14:19:19 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730141926_883eb02c-9c94-479e-8d3e-e2784fbb3840): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-02-02")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730141926_883eb02c-9c94-479e-8d3e-e2784fbb3840); Time taken: 0.423 seconds
INFO  : Executing command(queryId=hive_20200730141926_883eb02c-9c94-479e-8d3e-e2784fbb3840): ALTER TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY ADD PARTITION(Data_Dt="2019-02-02")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730141926_883eb02c-9c94-479e-8d3e-e2784fbb3840); Time taken: 0.104 seconds
INFO  : OK
No rows affected (0.601 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730141933_c0e21a23-9599-4ed7-83d4-ca8cda6659ee): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-02-02") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202 WHERE to_date("2019-02-02") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-03")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:od_id, type:string, comment:null), FieldSchema(name:line_merge_ind, type:int, comment:null), FieldSchema(name:clr_dt, type:string, comment:null), FieldSchema(name:ud_data_proc_ind, type:int, comment:null), FieldSchema(name:ud_proc_dt, type:string, comment:null), FieldSchema(name:ud_proc_tm, type:string, comment:null), FieldSchema(name:acc_tm, type:timestamp, comment:null), FieldSchema(name:pass_line_cnt, type:int, comment:null), FieldSchema(name:pass_line_desc, type:string, comment:null), FieldSchema(name:pass_lineid_desc, type:string, comment:null), FieldSchema(name:od_walk_duration, type:int, comment:null), FieldSchema(name:line_value_desc, type:string, comment:null), FieldSchema(name:pass_line_and_traf_desc, type:string, comment:null), FieldSchema(name:pass_station_desc, type:string, comment:null), FieldSchema(name:route_id, type:string, comment:null), FieldSchema(name:_c15, type:string, comment:null), FieldSchema(name:entry_station_id, type:string, comment:null), FieldSchema(name:entry_line_id, type:string, comment:null), FieldSchema(name:exit_station_id, type:string, comment:null), FieldSchema(name:exit_line_id, type:string, comment:null), FieldSchema(name:od_entry_station_id, type:string, comment:null), FieldSchema(name:od_entry_line_id, type:string, comment:null), FieldSchema(name:_c22, type:string, comment:null), FieldSchema(name:od_exit_station_id, type:string, comment:null), FieldSchema(name:od_exit_line_id, type:string, comment:null), FieldSchema(name:_c25, type:string, comment:null), FieldSchema(name:entry_time, type:timestamp, comment:null), FieldSchema(name:entry_dt, type:string, comment:null), FieldSchema(name:entry_tm, type:string, comment:null), FieldSchema(name:exit_time, type:timestamp, comment:null), FieldSchema(name:exit_dt, type:string, comment:null), FieldSchema(name:exit_tm, type:string, comment:null), FieldSchema(name:prod_id, type:string, comment:null), FieldSchema(name:tkt_id, type:string, comment:null), FieldSchema(name:tkt_seq_num, type:string, comment:null), FieldSchema(name:tkt_life_prd, type:int, comment:null), FieldSchema(name:entry_gate_id, type:string, comment:null), FieldSchema(name:exit_gate_id, type:string, comment:null), FieldSchema(name:file_name_and_record, type:string, comment:null), FieldSchema(name:base_data_ver_num, type:int, comment:null), FieldSchema(name:_c40, type:string, comment:null), FieldSchema(name:proc_num, type:string, comment:null), FieldSchema(name:entry_opr_pty_id, type:string, comment:null), FieldSchema(name:exit_opr_pty_id, type:string, comment:null), FieldSchema(name:od_entry_opr_pty_id, type:string, comment:null), FieldSchema(name:od_exit_opr_pty_id, type:string, comment:null), FieldSchema(name:entry_walk_duration, type:int, comment:null), FieldSchema(name:exit_walk_duration, type:int, comment:null), FieldSchema(name:entry_wait_duration, type:int, comment:null), FieldSchema(name:cch_irgul_list, type:string, comment:null), FieldSchema(name:line_modify_ind, type:int, comment:null), FieldSchema(name:_c51, type:string, comment:null), FieldSchema(name:sam_id, type:string, comment:null), FieldSchema(name:discount_type_cd, type:int, comment:null), FieldSchema(name:total_score, type:decimal(18,0), comment:null), FieldSchema(name:expc_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:actl_pay_amt, type:decimal(18,2), comment:null), FieldSchema(name:purse_prod_bal, type:decimal(18,0), comment:null), FieldSchema(name:trans_before_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:trans_after_sum_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_date, type:string, comment:null), FieldSchema(name:discount_params, type:int, comment:null), FieldSchema(name:card_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:xfer_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:sum_discount_amt, type:decimal(18,0), comment:null), FieldSchema(name:integral_start_value, type:decimal(18,0), comment:null), FieldSchema(name:period_discount_start_tm, type:string, comment:null), FieldSchema(name:period_discount_end_tm, type:string, comment:null), FieldSchema(name:_c69, type:string, comment:null), FieldSchema(name:comp_amt, type:decimal(18,0), comment:null), FieldSchema(name:_c71, type:string, comment:null), FieldSchema(name:_c72, type:string, comment:null), FieldSchema(name:_c73, type:string, comment:null), FieldSchema(name:_c74, type:string, comment:null), FieldSchema(name:mot_entry_citycode, type:string, comment:null), FieldSchema(name:mot_exit_citycode, type:string, comment:null), FieldSchema(name:mot_entry_industrycode, type:string, comment:null), FieldSchema(name:mot_exit_industrycode, type:string, comment:null), FieldSchema(name:mot_entry_stationcode, type:string, comment:null), FieldSchema(name:mot_exit_stationcode, type:string, comment:null), FieldSchema(name:mot_entry_deviceid, type:string, comment:null), FieldSchema(name:mot_exit_deviceid, type:string, comment:null), FieldSchema(name:mot_entry_time, type:timestamp, comment:null), FieldSchema(name:mot_exit_time, type:timestamp, comment:null), FieldSchema(name:mot_max_transvalue, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_exit_line, type:decimal(3,0), comment:null), FieldSchema(name:mot_entry_balance, type:decimal(10,0), comment:null), FieldSchema(name:mot_entry_purse_balance, type:decimal(10,0), comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20200730141933_c0e21a23-9599-4ed7-83d4-ca8cda6659ee); Time taken: 0.762 seconds
INFO  : Executing command(queryId=hive_20200730141933_c0e21a23-9599-4ed7-83d4-ca8cda6659ee): INSERT OVERWRITE TABLE BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY PARTITION(Data_Dt="2019-02-02") SELECT OD_ID,Line_Merge_Ind,Clr_Dt,UD_Data_Proc_Ind,UD_Proc_Dt,UD_Proc_Tm,ACC_Tm,Pass_Line_Cnt,Pass_Line_Desc,Pass_LineID_Desc,OD_Walk_Duration,Line_Value_Desc,Pass_Line_And_Traf_Desc,Pass_Station_Desc,Route_ID,trim(Clr_Method_Cd),Entry_Station_ID,Entry_Line_ID,Exit_Station_ID,Exit_Line_ID,OD_Entry_Station_ID,OD_Entry_Line_ID,trim(OD_Entry_Trip_Drct_Cd),OD_Exit_Station_ID,OD_Exit_Line_ID,trim(OD_Exit_Trip_Drct_Cd),Entry_Time,Entry_Dt,Entry_Tm,Exit_Time,Exit_Dt,Exit_Tm,Prod_ID,Tkt_ID,Tkt_Seq_Num,Tkt_Life_Prd,Entry_Gate_Id,Exit_Gate_Id,File_Name_And_Record,Base_Data_Ver_Num,trim(UD_Data_Type_Cd),Proc_Num,Entry_Opr_Pty_ID,Exit_Opr_Pty_ID,OD_Entry_Opr_Pty_ID,OD_Exit_Opr_Pty_ID,Entry_Walk_Duration,Exit_Walk_Duration,Entry_Wait_Duration,CCH_Irgul_List,Line_Modify_Ind,trim(Load_File_Type_Cd),SAM_ID,Discount_Type_Cd,Total_Score,Expc_Pay_Amt,Actl_Pay_Amt,Purse_Prod_Bal,Trans_Before_Sum_Amt,Trans_After_Sum_Amt,Integral_Start_Date,Discount_Params,Card_Discount_Amt,Xfer_Discount_Amt,Period_Discount_Amt,Sum_Discount_Amt,Integral_Start_Value,Period_Discount_Start_Tm,Period_Discount_End_Tm,trim(Comp_Reason_Cd),Comp_Amt,trim(City_Cd),trim(Industry_Cd),trim(Tx_Cd),trim(Tx_Sub_Cd),MOT_ENTRY_CITYCODE,MOT_EXIT_CITYCODE,MOT_ENTRY_INDUSTRYCODE,MOT_EXIT_INDUSTRYCODE,MOT_ENTRY_STATIONCODE,MOT_EXIT_STATIONCODE,MOT_ENTRY_DEVICEID,MOT_EXIT_DEVICEID,MOT_ENTRY_TIME,MOT_EXIT_TIME,MOT_MAX_TRANSVALUE,MOT_ENTRY_LINE,MOT_EXIT_LINE,MOT_ENTRY_BALANCE,MOT_ENTRY_PURSE_BALANCE FROM BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202 WHERE to_date("2019-02-02") <= to_date(Data_Dt) AND to_date(Data_Dt) < to_date("2019-02-03")
INFO  : Query ID = hive_20200730141933_c0e21a23-9599-4ed7-83d4-ca8cda6659ee
INFO  : Total jobs = 3
INFO  : Launching Job 1 out of 3
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Running with YARN Application = application_1594011529082_14829
INFO  : Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1594011529082_14829
INFO  : Hive on Spark Session Web UI URL: http://cdh10.irc.com:35406
INFO  : 
Query Hive on Spark job[0] stages: [0]
INFO  : Spark job[0] status = RUNNING
INFO  : Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount
INFO  : 2020-07-30 14:19:52,885	Stage-0_0: 0(+1)/23	
INFO  : 2020-07-30 14:19:55,895	Stage-0_0: 0(+1)/23	
INFO  : 2020-07-30 14:19:56,901	Stage-0_0: 0(+2)/23	
INFO  : 2020-07-30 14:19:58,907	Stage-0_0: 0(+6)/23	
INFO  : 2020-07-30 14:20:01,916	Stage-0_0: 0(+7)/23	
INFO  : 2020-07-30 14:20:04,924	Stage-0_0: 0(+10)/23	
INFO  : 2020-07-30 14:20:05,926	Stage-0_0: 1(+13)/23	
INFO  : 2020-07-30 14:20:08,936	Stage-0_0: 1(+22)/23	
INFO  : 2020-07-30 14:20:11,943	Stage-0_0: 1(+22)/23	
INFO  : 2020-07-30 14:20:12,946	Stage-0_0: 2(+21)/23	
INFO  : 2020-07-30 14:20:13,949	Stage-0_0: 3(+20)/23	
INFO  : 2020-07-30 14:20:16,956	Stage-0_0: 4(+19)/23	
INFO  : 2020-07-30 14:20:18,961	Stage-0_0: 6(+17)/23	
INFO  : 2020-07-30 14:20:19,964	Stage-0_0: 9(+14)/23	
INFO  : 2020-07-30 14:20:21,968	Stage-0_0: 10(+13)/23	
INFO  : 2020-07-30 14:20:22,971	Stage-0_0: 19(+4)/23	
INFO  : 2020-07-30 14:20:25,977	Stage-0_0: 19(+4)/23	
INFO  : 2020-07-30 14:20:26,981	Stage-0_0: 20(+3)/23	
INFO  : 2020-07-30 14:20:27,983	Stage-0_0: 23/23 Finished	
INFO  : Spark job[0] finished successfully in 37.15 second(s)
INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode
INFO  : Stage-4 is selected by condition resolver.
INFO  : Stage-3 is filtered out by condition resolver.
INFO  : Stage-5 is filtered out by condition resolver.
INFO  : Starting task [Stage-4:MOVE] in serial mode
INFO  : Moving data to directory hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-02/.hive-staging_hive_2020-07-30_14-19-33_285_7011307289264458593-3/-ext-10000 from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-02/.hive-staging_hive_2020-07-30_14-19-33_285_7011307289264458593-3/-ext-10002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table bmnc_pdata.t80_passenger_flow_modify partition (data_dt=2019-02-02) from hdfs://nameservice1/user/hive/warehouse/bmnc_pdata.db/t80_passenger_flow_modify/data_dt=2019-02-02/.hive-staging_hive_2020-07-30_14-19-33_285_7011307289264458593-3/-ext-10000
INFO  : Starting task [Stage-2:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20200730141933_c0e21a23-9599-4ed7-83d4-ca8cda6659ee); Time taken: 54.839 seconds
INFO  : OK
3,950,777 rows affected (55.642 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730142035_a19c8cd6-081a-428f-8697-82c60fcd0ebb): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730142035_a19c8cd6-081a-428f-8697-82c60fcd0ebb); Time taken: 0.418 seconds
INFO  : Executing command(queryId=hive_20200730142035_a19c8cd6-081a-428f-8697-82c60fcd0ebb): DROP TABLE BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190202
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730142035_a19c8cd6-081a-428f-8697-82c60fcd0ebb); Time taken: 1.411 seconds
INFO  : OK
No rows affected (1.908 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
ls: `/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190203': No such file or directory
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730142048_da9acfeb-c5f1-49dc-b7e9-ff808a94ea55): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190203
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730142048_da9acfeb-c5f1-49dc-b7e9-ff808a94ea55); Time taken: 0.41 seconds
INFO  : Executing command(queryId=hive_20200730142048_da9acfeb-c5f1-49dc-b7e9-ff808a94ea55): DROP TABLE IF EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190203
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730142048_da9acfeb-c5f1-49dc-b7e9-ff808a94ea55); Time taken: 0.01 seconds
INFO  : OK
No rows affected (0.494 seconds)
INFO  : Compiling command(queryId=hive_20200730142048_917625a9-498d-4e94-893b-f311bb049cbe): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190203 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190203"
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730142048_917625a9-498d-4e94-893b-f311bb049cbe); Time taken: 0.215 seconds
INFO  : Executing command(queryId=hive_20200730142048_917625a9-498d-4e94-893b-f311bb049cbe): CREATE TABLE IF NOT EXISTS BMNC_PDATA_EXTERNAL.T80_PASSENGER_FLOW_MODIFY20190203 ( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`data_dt` string comment "数据日期",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") ROW FORMAT DELIMITED FIELDS TERMINATED BY "\u0001" LOCATION "/ods/BMNC_PDATA_EXTERNAL/T80_PASSENGER_FLOW_MODIFY20190203"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20200730142048_917625a9-498d-4e94-893b-f311bb049cbe); Time taken: 1.469 seconds
INFO  : OK
No rows affected (1.706 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://10.254.16.3:10000/default;principal=hive/cdh03.irc.com@IRC.COM
Connected to: Apache Hive (version 2.1.1-cdh6.3.2)
Driver: Hive JDBC (version 2.1.1-cdh6.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20200730142056_7f1d2b0a-f68e-472b-b82b-1fd6c00c32a3): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20200730142056_7f1d2b0a-f68e-472b-b82b-1fd6c00c32a3); Time taken: 0.428 seconds
INFO  : Executing command(queryId=hive_20200730142056_7f1d2b0a-f68e-472b-b82b-1fd6c00c32a3): CREATE TABLE IF NOT EXISTS BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY( `od_id` string comment "od编号",`line_merge_ind` int comment "线路合并标志",`clr_dt` string comment "清分日期",`ud_data_proc_ind` int comment "ud数据处理标志",`ud_proc_dt` string comment "ud处理日期",`ud_proc_tm` string comment "ud处理时间",`acc_tm` timestamp comment "acc时间戳",`pass_line_cnt` int comment "途经线路条数",`pass_line_desc` string comment "途经线路详情描述",`pass_lineid_desc` string comment "途经线路编号描述",`od_walk_duration` int comment "od全程走行时长",`line_value_desc` string comment "线路票款信息描述",`pass_line_and_traf_desc` string comment "途经线路及换乘描述",`pass_station_desc` string comment "途经车站详情描述",`route_id` string comment "路径编号",`clr_method_cd` string comment "清分方式代码",`entry_station_id` string comment "进站车站编号",`entry_line_id` string comment "进站线路编号",`exit_station_id` string comment "出站车站编号",`exit_line_id` string comment "出站线路编号",`od_entry_station_id` string comment "od进站车站编号",`od_entry_line_id` string comment "od进站线路编号",`od_entry_trip_drct_cd` string comment "od进站行车方向代码",`od_exit_station_id` string comment "od出站车站编号",`od_exit_line_id` string comment "od出站线路编号",`od_exit_trip_drct_cd` string comment "od出站行车方向代码",`entry_time` timestamp comment "进站时间戳",`entry_dt` string comment "进站日期",`entry_tm` string comment "进站时间",`exit_time` timestamp comment "出站时间戳",`exit_dt` string comment "出站日期",`exit_tm` string comment "出站时间",`prod_id` string comment "产品编号",`tkt_id` string comment "票卡编号",`tkt_seq_num` string comment "票卡序列号",`tkt_life_prd` int comment "票卡生命周期",`entry_gate_id` string comment "进站闸机编号",`exit_gate_id` string comment "出站闸机编号",`file_name_and_record` string comment "文件名和行号",`base_data_ver_num` int comment "基础数据版本号",`ud_data_type_cd` string comment "ud数据类型代码",`proc_num` string comment "进程号",`entry_opr_pty_id` string comment "进站运营商当事人编号",`exit_opr_pty_id` string comment "出站运营商当事人编号",`od_entry_opr_pty_id` string comment "od进站运营商当事人编号",`od_exit_opr_pty_id` string comment "od出站运营商当事人编号",`entry_walk_duration` int comment "进站走行时长",`exit_walk_duration` int comment "出站走行时长",`entry_wait_duration` int comment "进站等候时长",`cch_irgul_list` string comment "cch异常列表",`line_modify_ind` int comment "修正标志",`load_file_type_cd` string comment "加载文件类型代码",`sam_id` string comment "sam标识号",`discount_type_cd` int comment "积分优惠类型代码",`total_score` decimal(18,0) comment "累计积分",`expc_pay_amt` decimal(18,2) comment "应付金额",`actl_pay_amt` decimal(18,2) comment "实际支付金额",`purse_prod_bal` decimal(18,0) comment "钱包产品余额",`trans_before_sum_amt` decimal(18,0) comment "交易前累积金额",`trans_after_sum_amt` decimal(18,0) comment "交易后累积金额",`integral_start_date` string comment "累积开始日期",`discount_params` int comment "优惠属性值",`card_discount_amt` decimal(18,0) comment "卡种折扣金额",`xfer_discount_amt` decimal(18,0) comment "换乘折扣金额",`period_discount_amt` decimal(18,0) comment "时段折扣金额",`sum_discount_amt` decimal(18,0) comment "累积折扣金额",`integral_start_value` decimal(18,0) comment "累积折扣积分起始值",`period_discount_start_tm` string comment "时段折扣开始时间",`period_discount_end_tm` string comment "时段折扣结束时间",`comp_reason_cd` string comment "补票原因代码",`comp_amt` decimal(18,0) comment "补票金额",`city_cd` string comment "城市代码",`industry_cd` string comment "行业代码",`tx_cd` string comment "交易码",`tx_sub_cd` string comment "交易子码",`mot_entry_citycode` string comment "进闸城市代码",`mot_exit_citycode` string comment "出闸城市代码",`mot_entry_industrycode` string comment "进闸机构标识",`mot_exit_industrycode` string comment "出闸机构标识",`mot_entry_stationcode` string comment "进闸站点",`mot_exit_stationcode` string comment "出闸站点",`mot_entry_deviceid` string comment "进闸终端编号",`mot_exit_deviceid` string comment "出闸终端编号",`mot_entry_time` timestamp comment "进闸时间",`mot_exit_time` timestamp comment "出闸时间",`mot_max_transvalue` decimal(10,0) comment "最大消费金额",`mot_entry_line` decimal(3,0) comment "入站线路号",`mot_exit_line` decimal(3,0) comment "出站线路号",`mot_entry_balance` decimal(10,0) comment "进站交易金额",`mot_entry_purse_balance` decimal(10,0) comment "进站钱包余额") PARTITIONED BY (Data_Dt string) STORED AS ORC tblproperties ("orc.compress" = "SNAPPY")
INFO  : Completed executing command(queryId=hive_20200730142056_7f1d2b0a-f68e-472b-b82b-1fd6c00c32a3); Time taken: 0.003 seconds
INFO  : OK
No rows affected (0.503 seconds)
Beeline version 2.1.1-cdh6.3.2 by Apache Hive
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/07/30 14:21:00 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/07/30 14:21:01 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/07/30 14:21:01 INFO teradata.TeradataManagerFactory: Loaded connector factory for 'Cloudera Connector Powered by Teradata' on version 1.7c6
20/07/30 14:21:01 INFO manager.SqlManager: Using default fetchSize of 1000
20/07/30 14:21:01 INFO options.ExtraOptions: Parsing extra arguments
20/07/30 14:21:01 INFO options.OptionsCompatibility: Checking options compatibility
20/07/30 14:21:01 INFO teradata.SchemaInjector: Using connection string: jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 14:21:01 INFO tool.CodeGenTool: Beginning code generation
20/07/30 14:21:02 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/07/30 14:21:04 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-operator/compile/1a1c4a360c8b180844587cf0d4741ce9/QueryResult.java to /home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java. Error: Destination '/home/operator/work/datatom/hiveTools/subwaybigtab/./QueryResult.java' already exists
20/07/30 14:21:04 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-operator/compile/1a1c4a360c8b180844587cf0d4741ce9/QueryResult.jar
20/07/30 14:21:04 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')) FROM (SELECT * FROM BMNC_PDATA.T80_PASSENGER_FLOW_MODIFY WHERE CAST('2019-02-03' AS DATE FORMAT 'YYYY-MM-DD') <= Data_Dt AND Data_Dt < CAST('2019-02-04' AS DATE FORMAT 'YYYY-MM-DD') AND (1 = 1) ) sqoop_import_query_alias
20/07/30 14:21:10 INFO tool.ImportTool: Incremental import based on column CAST(Data_Dt AS DATE FORMAT 'YYYY-MM-DD')
20/07/30 14:21:10 INFO tool.ImportTool: Upper bound value: '2019-02-03'
20/07/30 14:21:10 INFO teradata.TeradataManager: Beginning Teradata query based import
20/07/30 14:21:10 INFO mapreduce.ImportJobBase: Beginning query import.
20/07/30 14:21:10 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 14:21:10 INFO common.ConnectorPlugin: load plugins in jar:file:/var/lib/sqoop/sqoop-connector-teradata-1.7c6.jar!/teradata.connector.plugins.xml
20/07/30 14:21:11 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 14:21:11 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor starts at:  1596090071359
20/07/30 14:21:12 INFO utils.TeradataUtils: the input database product is Teradata
20/07/30 14:21:12 INFO utils.TeradataUtils: the input database version is 14.0
20/07/30 14:21:12 INFO utils.TeradataUtils: the jdbc driver version is 16.20
20/07/30 14:21:12 INFO processor.TeradataInputProcessor: the teradata connector for hadoop version is: null
20/07/30 14:21:12 INFO processor.TeradataInputProcessor: input jdbc properties are jdbc:teradata://10.254.101.198/DATABASE=BMNC_PDATA,TMODE=TERA,CHARSET=UTF8
20/07/30 14:21:13 INFO processor.TeradataInputProcessor: the number of mappers are 1
20/07/30 14:21:13 INFO processor.TeradataInputProcessor: input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor ends at:  1596090073196
20/07/30 14:21:13 INFO processor.TeradataInputProcessor: the total elapsed time of input preprocessor com.teradata.connector.teradata.processor.TeradataSplitByPartitionProcessor is: 1s
20/07/30 14:21:13 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
20/07/30 14:21:13 INFO hdfs.DFSClient: Created token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596090073948, maxDate=1596694873948, sequenceNumber=53846, masterKeyId=57 on ha-hdfs:nameservice1
20/07/30 14:21:14 INFO security.TokenCache: Got dt for hdfs://nameservice1; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596090073948, maxDate=1596694873948, sequenceNumber=53846, masterKeyId=57)
20/07/30 14:21:14 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hive/.staging/job_1594011529082_14830
20/07/30 14:21:17 WARN mapred.ResourceMgrDelegate: getBlacklistedTrackers - Not implemented yet
20/07/30 14:21:17 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 14:21:17 INFO Configuration.deprecation: yarn.resourcemanager.zk-address is deprecated. Instead, use hadoop.zk.address
20/07/30 14:21:17 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/07/30 14:21:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1594011529082_14830
20/07/30 14:21:17 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:nameservice1, Ident: (token for hive: HDFS_DELEGATION_TOKEN owner=hive@IRC.COM, renewer=yarn, realUser=, issueDate=1596090073948, maxDate=1596694873948, sequenceNumber=53846, masterKeyId=57)]
20/07/30 14:21:17 INFO conf.Configuration: resource-types.xml not found
20/07/30 14:21:17 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/07/30 14:21:18 INFO impl.YarnClientImpl: Submitted application application_1594011529082_14830
20/07/30 14:21:18 INFO mapreduce.Job: The url to track the job: http://cdh02.irc.com:8088/proxy/application_1594011529082_14830/
20/07/30 14:21:18 INFO mapreduce.Job: Running job: job_1594011529082_14830
20/07/30 14:21:27 INFO mapreduce.Job: Job job_1594011529082_14830 running in uber mode : false
20/07/30 14:21:27 INFO mapreduce.Job:  map 0% reduce 0%
